# PIPELINE DE CAPTURA Y CLASIFICACI√ìN ‚Äì FASE 0

## üéØ Objetivo de la fase
Validar el flujo completo del sistema con un √∫nico sensor, un ejercicio ficticio, y etiquetas simples de ‚Äúcorrecto‚Äù / ‚Äúincorrecto‚Äù. Esto permitir√° tener una primera IA funcional y testear el ciclo completo de captura, visualizaci√≥n, segmentaci√≥n, entrenamiento y evaluaci√≥n.

---

## 1. Captura
- **Sensor**: MPU6050 conectado a ESP32 (I2C)
- **Frecuencia de muestreo esperada**: ~100-200 Hz (seg√∫n el c√≥digo del ESP32)
- **Datos enviados**: `timestamp, yaw, pitch, roll`
- **Formato CSV de guardado**:  
  `rep_id, timestamp, yaw, pitch, roll, etiqueta`
- **Etiquetas posibles**: `correcto`, `incorrecto`

---

## 2. Preprocesamiento
- Agrupaci√≥n por repetici√≥n (`rep_id`)
- Normalizaci√≥n del tiempo (inicio de repetici√≥n = 0)
- Posibilidad de descartar outliers en un futuro
- Separaci√≥n en `train` y `test`

---

## 3. Segmentaci√≥n
- Segmentaci√≥n manual mediante teclado:
  - `q` para iniciar repetici√≥n correcta
  - `w` para finalizar repetici√≥n correcta
  - `e` para iniciar repetici√≥n incorrecta
  - `r` para finalizar repetici√≥n incorrecta
- Se registra cada repetici√≥n completa con un `rep_id`

---

## 4. Etiquetado
- En tiempo real mediante teclado
- üì∑ Posible validaci√≥n posterior mediante v√≠deo (sincronizaci√≥n manual por ahora)
- Se eval√∫a visualmente cada repetici√≥n con Matplotlib para asegurar la coherencia

---

## 5. Extracci√≥n de caracter√≠sticas
Por cada repetici√≥n se calculan:
- **yaw / pitch / roll**:
  - Media
  - Desviaci√≥n est√°ndar
  - Rango

üîú Ampliaciones previstas:
- Duraci√≥n (tiempo total)
- Velocidad media
- Aceleraci√≥n angular estimada
- N√∫mero de picos
- Energ√≠a de la se√±al

---

## 6. Entrenamiento
- Librer√≠a: `scikit-learn`
- Modelos probados:
  - SVM (Support Vector Machine) con kernel lineal
- M√©tricas utilizadas:
  - Accuracy (exactitud global)
  - Precision, Recall, F1-score por clase
  - Matriz de confusi√≥n

üîú Pr√≥ximos modelos:
- √Årboles de decisi√≥n (interpretable)
- Random Forest
- KNN
- Regresi√≥n log√≠stica
- Deep Learning (Keras) cuando haya m√°s datos

---

## 7. Evaluaci√≥n
- Divisi√≥n 70/30 entre train/test
- Visualizaci√≥n de matriz de confusi√≥n
- An√°lisis de errores
- Validaci√≥n cruzada en el futuro
