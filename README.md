# mpu6050-esp32-visualizer

Este proyecto estÃ¡ licenciado bajo CC BY-NC-SA 4.0. MÃ¡s informaciÃ³n: https://creativecommons.org/licenses/by-nc-sa/4.0/

TODO
- conexiÃ³n wifi
- protocolo comunicaciÃ³n asÃ­ncrono
- 
## VersiÃ³n 4.0:
Cambio sustancial. ImplementaciÃ³n propia con ayuda de ChatGPT frente a la generaciÃ³n total por parte de la IA de versiones anteriores.
# ğŸ“ Arquitectura del Sistema BiomecÃ¡nico (v4.0)

Este documento describe la estructura modular del sistema biomecÃ¡nico, preparada para escalar desde 1 hasta 6 IMUs, mÃºltiples modos de operaciÃ³n, e interfaces visuales avanzadas (2D, 3D, heatmap). La arquitectura estÃ¡ dividida en capas bien diferenciadas, facilitando el mantenimiento, testeo e incorporaciÃ³n de nuevas funcionalidades.

---

## ğŸ—‚ Estructura de Carpetas
## ğŸ—‚ Estructura del Proyecto

```plaintext
project_root/
â”‚
â”œâ”€â”€ core/                    # LÃ³gica de negocio (sin Qt ni matplotlib)
â”‚   â”œâ”€â”€ imu/                 # GestiÃ³n de sensores
â”‚   â”‚   â”œâ”€â”€ imu.py           # Clase IMUSensor (un sensor)
â”‚   â”‚   â””â”€â”€ manager.py       # SensorManager (N sensores)
â”‚   â”‚
â”‚   â”œâ”€â”€ acquisition.py       # DataRecorder + CaptureController (seÃ±ales Qt)
â”‚   â”œâ”€â”€ features.py          # ExtracciÃ³n de caracterÃ­sticas desde raw data
â”‚   â”œâ”€â”€ training.py          # TrainingManager (entrenar, validar, guardar)
â”‚   â””â”€â”€ predictor.py         # PredictorManager (cargar modelo, predecir)
â”‚
â”œâ”€â”€ visualization/           # RepresentaciÃ³n visual (sin Qt)
â”‚   â”œâ”€â”€ plot2d.py            # GrÃ¡ficas de series temporales
â”‚   â”œâ”€â”€ heatmap.py           # GeneraciÃ³n de mapas de calor
â”‚   â””â”€â”€ renderer3d.py        # Esqueleto 3D animado
â”‚
â”œâ”€â”€ ui/                      # Interfaz grÃ¡fica (Qt)
â”‚   â”œâ”€â”€ widgets/             # Widgets individuales por modo
â”‚   â”‚   â”œâ”€â”€ capture_widget.py
â”‚   â”‚   â”œâ”€â”€ training_widget.py
â”‚   â”‚   â”œâ”€â”€ offline_widget.py
â”‚   â”‚   â””â”€â”€ live_widget.py
â”‚   â”‚
â”‚   â””â”€â”€ main.py              # Ventana principal y gestor de modos
â”‚
â”œâ”€â”€ main.py                  # EjecuciÃ³n principal
â”‚
â””â”€â”€ tests/                   # Pruebas automÃ¡ticas
    â”œâ”€â”€ imu_test.py
    â”œâ”€â”€ acquisition_test.py
    â”œâ”€â”€ features_test.py
    â”œâ”€â”€ training_test.py
    â””â”€â”€ predictor_test.py
```

---

## ğŸ§  Capas y Responsabilidades

| Paquete       | Responsabilidad principal                                                   |
|---------------|------------------------------------------------------------------------------|
| `core/imu`    | Manejo individual y grupal de sensores IMU.                                 |
| `core/`       | LÃ³gica de grabaciÃ³n, segmentaciÃ³n, entrenamiento y predicciÃ³n.              |
| `visualization/` | GeneraciÃ³n de grÃ¡ficas, mapas de calor y animaciÃ³n 3D.                    |
| `ui/`         | Interfaz Qt: botones, grÃ¡ficos, controles e interacciÃ³n visual.             |
| `tests/`      | Tests unitarios para asegurar que todo funcione sin hardware ni GUI.        |

---

## ğŸ”„ Flujo de Datos: Modo â€œCaptura y SegmentaciÃ³nâ€

1. El usuario pulsa **Start** en `CaptureWidget`.
2. El widget lanza el `CaptureController`, que a su vez inicia un `DataRecorder` con un `SensorManager`.
3. El `SensorManager` gestiona mÃºltiples `IMUSensor` y retorna un diccionario con las lecturas por sensor:

    ```python
    {
      "imu1": {"t":â€¦, "yaw":â€¦, "pitch":â€¦, "roll":â€¦},
      ...
      "imu6": {...}
    }
    ```

4. El `DataRecorder`:
   - ğŸ“ Escribe los datos en un archivo CSV.
   - ğŸ• Detecta el final de cada repeticiÃ³n.
   - ğŸ“¡ Emite seÃ±ales Qt (`data_ready`) que permiten:
     - ğŸ“ˆ Actualizar grÃ¡ficas 2D.
     - ğŸŒ¡ï¸ Pintar un heatmap.
     - ğŸ¦´ Animar la vista 3D.

> **Nota:** Los widgets Qt **no contienen lÃ³gica de negocio**. Solo conectan botones con controladores y reciben datos procesados desde `core/`.

---

## ğŸ§± Estructura de Clases Clave

### `IMUSensor`
- Representa un Ãºnico sensor IMU.
- Se conecta por puerto, lee y entrega orientaciÃ³n (`yaw`, `pitch`, `roll`).

### `SensorManager`
- Maneja mÃºltiples objetos `IMUSensor`.
- Devuelve un snapshot sincronizado de todos los sensores activos.

### `DataRecorder`
- Controla la grabaciÃ³n continua de datos desde los sensores.
- Segmenta repeticiones.
- Escribe los datos y sus etiquetas en un archivo CSV.

### `CaptureController`
- Clase basada en `QObject` de Qt.
- Emite seÃ±ales (`data_ready`) para actualizar widgets grÃ¡ficos.

### `TrainingManager` / `PredictorManager`
- Entrenan modelos de clasificaciÃ³n a partir del CSV etiquetado.
- Predicen la clase/tÃ©cnica de ejecuciÃ³n de nuevas repeticiones.

---

## âš™ï¸ Escalabilidad: hasta 6 IMUs

- El `SensorManager` puede manejar un nÃºmero arbitrario de sensores configurados desde un archivo `.json` o `.ini`.
- Cada IMU tiene su propia serie de datos en el CSV y en la visualizaciÃ³n 2D.
- La vista 3D (`renderer3d.py`) utiliza las orientaciones de los 6 sensores para componer un esqueleto animado.
- **No es necesario modificar la interfaz grÃ¡fica** para aÃ±adir mÃ¡s sensores, basta con actualizar la configuraciÃ³n y la lÃ³gica del `renderer3d`.

---

## âœ… Ventajas de esta Arquitectura

- ğŸ”’ **SeparaciÃ³n clara** entre lÃ³gica y presentaciÃ³n (GUI).
- ğŸ” **ReutilizaciÃ³n** de mÃ³dulos en distintos modos o interfaces (CLI, GUI, batch).
- ğŸ§ª **Testabilidad total**: la lÃ³gica se puede testear sin Qt ni hardware.
- ğŸš€ **Escalabilidad real**: nuevos sensores, ejercicios o visualizaciones se integran sin reestructurar el sistema.
- ğŸ§© **Modularidad**: los componentes se pueden intercambiar fÃ¡cilmente (p. ej. cambiar SVM por CNN).

   

---

---

## VersiÃ³n 3.0:

Cambio de interfaz grÃ¡fica do Dock Widget. Errores en funionalidades

## VersiÃ³n 2.1:

AÃ±adir elemento grÃ¡ficos.


## VersiÃ³n 2.0:

## âœ… Objetivo de esta versiÃ³n

Validar un pipeline completo de clasificaciÃ³n binaria (**correcto** vs. **incorrecto**) de repeticiones usando un Ãºnico sensor IMU (MPU6050), orientado a ejercicios simples (prototipo tipo "S").

---

## ğŸ§ª Dataset utilizado

- Sensor colocado en: **muÃ±eca derecha** realizando un curl de bÃ­ceps donde cada repeticiÃ³n dura 4" (correcto-completo, incorrecto-medio rango)
- N.Âº de repeticiones: **20 correctas** + **20 incorrectas**.
- Etiquetado en tiempo real mediante teclado.
- Datos registrados: `timestamp, yaw, pitch, roll, etiqueta`
- Formato CSV: una fila por muestra, agrupadas por `rep_id`

---

## ğŸ§  CaracterÃ­sticas extraÃ­das por repeticiÃ³n

Para cada repeticiÃ³n, el sistema agrupa todas las muestras y calcula las siguientes **23 caracterÃ­sticas** (features) que resumen la ejecuciÃ³n:

### ğŸ“Š EstadÃ­sticas bÃ¡sicas (por eje: yaw, pitch, roll)
- `mean`: valor medio de la seÃ±al
- `std`: desviaciÃ³n estÃ¡ndar (variabilidad)
- `range`: diferencia entre el valor mÃ¡ximo y mÃ­nimo

### â±ï¸ DinÃ¡micas (por eje)
- `velocity_mean`: velocidad angular media (`Î”Ã¡ngulo / Î”tiempo`)
- `velocity_max`: velocidad angular mÃ¡xima (pico de velocidad)
- `num_peaks`: nÃºmero de picos detectados en la curva del eje (con `scipy.signal.find_peaks`)

### âŒ› DuraciÃ³n total de la repeticiÃ³n
- `duration`: duraciÃ³n total en segundos (`t_final âˆ’ t_inicial`)

### ğŸ”— CorrelaciÃ³n entre ejes
- `corr_yaw_pitch`
- `corr_yaw_roll`
- `corr_pitch_roll`

### âš¡ EnergÃ­a total
- `energy_total`: suma de la energÃ­a (cuadrado RMS) de yaw, pitch y roll

---

## ğŸ¤– Modelos comparados

Se entrenan y comparan **3 clasificadores** con `scikit-learn`:

1. **SVM (Support Vector Machine)** â€“ lineal  
   - Encuentra un plano Ã³ptimo que separa las clases.
   - Robusto con pocas muestras y alto nÃºmero de caracterÃ­sticas.

2. **Ãrbol de decisiÃ³n**  
   - Clasifica haciendo preguntas como â€œÂ¿roll_range > 35?â€
   - Muy interpretable, Ãºtil para entender reglas.

3. **KNN (k=5)**  
   - Clasifica en funciÃ³n de los 5 vecinos mÃ¡s cercanos.
   - Requiere mÃ¡s muestras para rendir bien.

---

## ğŸ“‰ MÃ©tricas utilizadas

Tras dividir el dataset en entrenamiento y test (70/30), se calcula:

- **Accuracy**: % de aciertos globales.
- **Precision**: de todas las veces que el modelo predijo una clase, Â¿cuÃ¡ntas eran correctas?
- **Recall**: de todas las veces que una clase era real, Â¿cuÃ¡ntas fueron detectadas?
- **F1-score**: promedio balanceado entre precisiÃ³n y recall.
- **support**: nÃºmero real de muestras de cada clase en el conjunto de test.

### ğŸ“Œ Matriz de confusiÃ³n

Cada modelo genera una matriz 2x2:

|                      | Predicho: Incorrecto | Predicho: Correcto   |
|----------------------|----------------------|----------------------|
| **Real: Incorrecto** | Verdaderos negativos | Falsos negativos     |
| **Real: Correcto**   | Falsos positivos     | Verdaderos positivos |

---

## ğŸ§  InterpretaciÃ³n de resultados

- Un buen clasificador tendrÃ¡ la **diagonal principal con valores altos** (aciertos) y ceros fuera de ella.
- El anÃ¡lisis conjunto de **accuracy + matriz de confusiÃ³n** + **F1-score por clase** permite entender si el modelo estÃ¡ sesgado (p. ej. solo acierta una clase) o equilibrado.

---


## VersiÃ³n 1.1: Pruebas repositorio

## VersiÃ³n 1.0: Primera versiÃ³n estable con visualizaciÃ³n en tiempo real
# PIPELINE DE CAPTURA Y CLASIFICACIÃ“N â€“ FASE 0

## ğŸ¯ Objetivo de la fase
Validar el flujo completo del sistema con un Ãºnico sensor, un ejercicio ficticio, y etiquetas simples de â€œcorrectoâ€ / â€œincorrectoâ€. Esto permitirÃ¡ tener una primera IA funcional y testear el ciclo completo de captura, visualizaciÃ³n, segmentaciÃ³n, entrenamiento y evaluaciÃ³n.

---

## 1. Captura
- **Sensor**: MPU6050 conectado a ESP32 (I2C)
- **Frecuencia de muestreo esperada**: ~100-200 Hz (segÃºn el cÃ³digo del ESP32)
- **Datos enviados**: `timestamp, yaw, pitch, roll`
- **Formato CSV de guardado**:  
  `rep_id, timestamp, yaw, pitch, roll, etiqueta`
- **Etiquetas posibles**: `correcto`, `incorrecto`

---

## 2. Preprocesamiento
- AgrupaciÃ³n por repeticiÃ³n (`rep_id`)
- NormalizaciÃ³n del tiempo (inicio de repeticiÃ³n = 0)
- Posibilidad de descartar outliers en un futuro
- SeparaciÃ³n en `train` y `test`

---

## 3. SegmentaciÃ³n
- SegmentaciÃ³n manual mediante teclado:
  - `q` para iniciar repeticiÃ³n correcta
  - `w` para finalizar repeticiÃ³n correcta
  - `e` para iniciar repeticiÃ³n incorrecta
  - `r` para finalizar repeticiÃ³n incorrecta
- Se registra cada repeticiÃ³n completa con un `rep_id`

---

## 4. Etiquetado
- En tiempo real mediante teclado
- ğŸ“· Posible validaciÃ³n posterior mediante vÃ­deo (sincronizaciÃ³n manual por ahora)
- Se evalÃºa visualmente cada repeticiÃ³n con Matplotlib para asegurar la coherencia

---

## 5. ExtracciÃ³n de caracterÃ­sticas
Por cada repeticiÃ³n se calculan:
- **yaw / pitch / roll**:
  - Media
  - DesviaciÃ³n estÃ¡ndar
  - Rango

ğŸ”œ Ampliaciones previstas:
- DuraciÃ³n (tiempo total)
- Velocidad media
- AceleraciÃ³n angular estimada
- NÃºmero de picos
- EnergÃ­a de la seÃ±al

---

## 6. Entrenamiento
- LibrerÃ­a: `scikit-learn`
- Modelos probados:
  - SVM (Support Vector Machine) con kernel lineal
- MÃ©tricas utilizadas:
  - Accuracy (exactitud global)
  - Precision, Recall, F1-score por clase
  - Matriz de confusiÃ³n

ğŸ”œ PrÃ³ximos modelos:
- Ãrboles de decisiÃ³n (interpretable)
- Random Forest
- KNN
- RegresiÃ³n logÃ­stica
- Deep Learning (Keras) cuando haya mÃ¡s datos

---

## 7. EvaluaciÃ³n
- DivisiÃ³n 70/30 entre train/test
- VisualizaciÃ³n de matriz de confusiÃ³n
- AnÃ¡lisis de errores
- ValidaciÃ³n cruzada en el futuro

--
# ConexiÃ³n del MPU6050 al ESP32

El sensor MPU6050 se comunica mediante el protocolo I2C. AdemÃ¡s, se puede utilizar un pin de interrupciÃ³n para notificaciones como disponibilidad de nuevos datos.

### Sketch del MPU6050

Se puede encontrar en ./sketch/MPU6050_DMP_YPR_logger/MPU6050_DMP_YPR_logger.ino

### ğŸ§  Pines del MPU6050

| Pin MPU6050       | FunciÃ³n                                    | ConexiÃ³n en ESP32                                                      |
|-------------------|--------------------------------------------|------------------------------------------------------------------------|
| **VCC**           | AlimentaciÃ³n                               | 3.3V del ESP32                                                         |
| **GND**           | Tierra                                     | GND del ESP32                                                          |
| **SCL**           | Clock de I2C                               | GPIO 22 (SCL del ESP32)                                                |
| **SDA**           | Datos de I2C                               | GPIO 21 (SDA del ESP32)                                                |
| **INT**           | InterrupciÃ³n por interrupciones de datos   | GPIO 25 (INT del ESP32)                                                |
| **XDA**           | Datos I2C para magnetÃ³metro (no usado)     | No conectado                                                           |
| **XCL**           | Clock I2C para magnetÃ³metro (no usado)     | No conectado                                                           |
| **AD0** o **ADO** | DirecciÃ³n I2C: LOW = `0x68`, HIGH = `0x69` | GND (recomendado usar `0x68` con lo que puede permanecer no conectado) |

> âš ï¸ Si usas mÃ¡s de un MPU6050 en el mismo bus I2C, puedes conectar AD0 a 3.3â€¯V en uno de ellos para usar `0x69` como direcciÃ³n secundaria.
